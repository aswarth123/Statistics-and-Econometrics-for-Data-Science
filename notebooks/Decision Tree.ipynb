{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree with pure Python (Without External Library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python and OOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [['Green',3,'Apple'],\n",
    "                 ['Yellow',3,'Apple'],\n",
    "                 ['Red',1,'Grape'],\n",
    "                 ['Red',1,'Grape'],\n",
    "                 ['Yellow',3,'Lemon']] #TOY DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Column Labels\n",
    "These are used to print tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"Color\",\"Diameter\",\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Finds Unique values for a column in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_vals(Data,col): #training_data,0\n",
    "    return set([row[col] for row in Data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple', 'Grape', 'Lemon'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_vals(training_data,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple': 2, 'Grape': 2, 'Lemon': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'Apple':2,'Grape':2,'Lemon':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count the number of each type in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(Data):\n",
    "    counts = {}\n",
    "    for row in Data:\n",
    "        label = row[-1]\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple': 2, 'Grape': 2, 'Lemon': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A Question is used to partition a dataset.\n",
    "\n",
    "This class just records a 'colum number (e.g., 0 for Color) and a column value (e.g., Green). The match method is used to compare the feature value in an example to the feature value stored in the question. See the demo below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "    def __init__(self,column,value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "    def match(self,example): #example means row --> ['Green',3,'Apple']\n",
    "        val = example[self.column]\n",
    "        return val == self.value #'Green' == 'Red', returns a boolean\n",
    "    def __repr__(self):\n",
    "        return \"Is %s %s %s?\" % (header[self.column],\"==\",str(self.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Is Color == Red?"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Question(0,\"Red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Diameter == 4?\n"
     ]
    }
   ],
   "source": [
    "q = Question(1,4)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.match(training_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Partitions a dataset.\n",
    "\n",
    "For each row in the dataset, check if it matches the question. If so, add it to 'true rows', otherwise, add it to 'false rows'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(Data,question):\n",
    "    true_rows,false_rows = [],[]\n",
    "    for row in Data: #row is also called example --> ['Green',3,'Apple']\n",
    "        if(question.match(row)):\n",
    "            true_rows.append(row) # --> [['Green',3,'Apple']]\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows,false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Rows:  [['Green', 3, 'Apple']]\n",
      "False Rows:  [['Yellow', 3, 'Apple'], ['Red', 1, 'Grape'], ['Red', 1, 'Grape'], ['Yellow', 3, 'Lemon']]\n"
     ]
    }
   ],
   "source": [
    "true_rows,false_rows = partition(training_data,\n",
    "                                 Question(0,'Green'))\n",
    "print('True Rows: ',true_rows)\n",
    "print('False Rows: ',false_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate the Gini Impurity for a list of rows.\n",
    "\n",
    "There are a few different ways to do this, I thought this one was the most concise. See: https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(Data):\n",
    "    counts = class_counts(Data)\n",
    "    impurity = 1\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl]/float(len(Data))\n",
    "#         print(prob_of_lbl)\n",
    "        impurity-=prob_of_lbl**2\n",
    "#         print(impurity)\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6399999999999999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Information Gain.\n",
    "\n",
    "The uncertainty of the starting node, minus the weighted impurity of two child nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left,right,current_impurity): #current impurity means GDS \n",
    "    #left means true, right means false\n",
    "    p = float(len(left))/(len(left)+len(right)) #prob of true rows\n",
    "    return current_impurity - p*gini(left) - (1-p)*gini(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_rows,false_rows = partition(training_data,\n",
    "                            Question(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37333333333333324"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_gain(true_rows,false_rows,gini(training_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Find the best question to ask by iterating over every feature / value and calculating the information gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(Data):\n",
    "    best_gain = 0\n",
    "    best_question = None\n",
    "    current_impurity = gini(Data) #Gds\n",
    "    n_features = len(Data[0]) - 1\n",
    "    for col in range(n_features): #0\n",
    "        values = unique_vals(Data,col) #[Green,Red,Yellow]\n",
    "        for val in values:\n",
    "            question = Question(col,val)\n",
    "            true_rows,false_rows = partition(Data,question)\n",
    "            if(len(true_rows) == 0 or len(false_rows)==0):\n",
    "                continue\n",
    "            gain = info_gain(true_rows,\n",
    "                             false_rows,\n",
    "                             current_impurity)\n",
    "            if gain>=best_gain:\n",
    "                best_gain, best_question = gain , question\n",
    "    return best_gain,best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Diameter == 3?\n",
      "0.37333333333333324\n"
     ]
    }
   ],
   "source": [
    "best_gain,best_question = find_best_split(training_data)\n",
    "print(best_question)\n",
    "print(best_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A Leaf node classifies data.\n",
    "\n",
    "This holds a dictionary of class (e.g., \"Mango\") -> number of times it appears in the rows from the training data that reach this leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self,Data):\n",
    "        self.predictions = class_counts(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A Decision Node asks a question.\n",
    "\n",
    "This holds a reference to the question, and to the two child nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    def __init__(self, question, true_branch,false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        #print(self.question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Builds the tree.\n",
    "\n",
    "Try partitioing the dataset on each of the unique attribute, \n",
    "calculate the information gain, \n",
    "and return the question that produces the highest gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(Data,i=0):\n",
    "    gain, question = find_best_split(Data) #FIND BEST QUESTION\n",
    "    \n",
    "\n",
    "    # Base case: no further info gain \n",
    "    # since we can ask no further questions,\n",
    "    # we'Ll return a leaf.\n",
    "    if gain == 0:\n",
    "        return Leaf(Data)\n",
    "    \n",
    "    # If we reach here, we have found a useful feature / value \n",
    "    # to partition on.\n",
    "    true_rows , false_rows = partition(Data,question)\n",
    "    \n",
    "    true_branch = build_tree(true_rows,i)\n",
    "    false_branch = build_tree(false_rows,i)\n",
    "    false_branch = build tree(false_rows)\n",
    "\n",
    "    # Return a Question node.\n",
    "    # This records the best feature / value to ask at this point, \n",
    "    # as well as the branches to follow\n",
    "    # dependingo on the answer.\n",
    "    return Decision_Node(question,true_branch,false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Decision_Node object at 0x0000025EE832F780>\n"
     ]
    }
   ],
   "source": [
    "my_tree = build_tree(training_data)\n",
    "print(my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node,spacing=\"\"):\n",
    "    if isinstance(node, Leaf):\n",
    "        print(spacing + \"Predict\",node.predictions)\n",
    "        return\n",
    "    print(spacing+str(node.question))\n",
    "    print(spacing + \"--> True:\")\n",
    "    print_tree(node.true_branch , spacing + \"\\t\")\n",
    "    \n",
    "    print(spacing + \"--> False:\")\n",
    "    print_tree(node.false_branch , spacing + \"\\t\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Diameter == 3?\n",
      "--> True:\n",
      "\tIs Color == Yellow?\n",
      "\t--> True:\n",
      "\t\tPredict {'Lemon': 1, 'Apple': 1}\n",
      "\t--> False:\n",
      "\t\tPredict {'Apple': 1}\n",
      "--> False:\n",
      "\tPredict {'Grape': 2}\n"
     ]
    }
   ],
   "source": [
    "print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_leaf(counts):\n",
    "    total = sum(counts.values())*1.0\n",
    "    probs = {}\n",
    "    for lbl in counts.keys():\n",
    "        probs[lbl] = str(int(counts[lbl]/total * 100)) + \"%\"\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row,node):\n",
    "    if isinstance(node,Leaf):\n",
    "        return node.predictions\n",
    "    \n",
    "    # Decide whether to follow the true-branch or the false-branch.\n",
    "    # Compate the feature / value stored in the node, \n",
    "    # to the example we're considering.\n",
    "    if node.question.match(row):\n",
    "        return classify(row,node.true_branch)\n",
    "    else:\n",
    "        return classify(row,node.false_branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = [\n",
    "    [\"Red\",1,\"Apple\"],\n",
    "    [\"Yellow\" , 3 , \"Apple\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparing actual and predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: Apple. Predicted: {'Grape': '100%'}\n",
      "Actual: Apple. Predicted: {'Apple': '50%', 'Lemon': '50%'}\n"
     ]
    }
   ],
   "source": [
    "for row in testing_data:\n",
    "    print(\"Actual: %s. Predicted: %s\" % \n",
    "          (row[-1],print_leaf(classify(row,my_tree))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training model with 2nd dataset to increase accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=[\"outlook\",\"temperature\",\"humidity\",\"wind\",\"decision\"]\n",
    "\n",
    "training_data2= [\n",
    "['sunny','hot','high','weak','no'],\n",
    "['sunny','hot','high','strong','no'],\n",
    "['overcast','hot','high','weak','yes'],\n",
    "['rain','mild','high','weak','yes'],\n",
    "['rain','cool','normal','weak','yes'],\n",
    "['rain','cool','normal','strong','no'],\n",
    "['overcast','cool','normal','strong','yes'],\n",
    "['sunny','mild','high','weak','no'],\n",
    "['sunny','cool','normal','weak','yes'],\n",
    "['rain','mild','normal','weak','yes'],\n",
    "['sunny','mild','normal','strong','yes'],\n",
    "['overcast','mild','high','strong','yes'],\n",
    "['overcast','hot','normal','weak','yes'],\n",
    "['rain','mild','high','strong','no'],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build the Decision tree with \"training_data2\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree2 = build_tree(training_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print The Final Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is outlook == overcast?\n",
      "--> True:\n",
      "\tPredict {'yes': 4}\n",
      "--> False:\n",
      "\tIs humidity == high?\n",
      "\t--> True:\n",
      "\t\tIs outlook == sunny?\n",
      "\t\t--> True:\n",
      "\t\t\tPredict {'no': 3}\n",
      "\t\t--> False:\n",
      "\t\t\tIs wind == strong?\n",
      "\t\t\t--> True:\n",
      "\t\t\t\tPredict {'no': 1}\n",
      "\t\t\t--> False:\n",
      "\t\t\t\tPredict {'yes': 1}\n",
      "\t--> False:\n",
      "\t\tIs wind == strong?\n",
      "\t\t--> True:\n",
      "\t\t\tIs temperature == cool?\n",
      "\t\t\t--> True:\n",
      "\t\t\t\tPredict {'no': 1}\n",
      "\t\t\t--> False:\n",
      "\t\t\t\tPredict {'yes': 1}\n",
      "\t\t--> False:\n",
      "\t\t\tPredict {'yes': 3}\n"
     ]
    }
   ],
   "source": [
    "print_tree(my_tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data2 = [\"overcast\",\"mild\",\"normal\",\"weak\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yes': 4}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(testing_data2,my_tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: {'yes': '100%'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted: %s\" % (print_leaf(classify(testing_data2,my_tree2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
